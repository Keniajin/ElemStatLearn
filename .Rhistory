# <<< Fit Model >>>
dat <- data.frame(x=x_train,y=as.factor(y_train))
svmfit <- glm(y~., data=dat, family=binomial)
#svmfit <- svm(y~.,data=dat,kernel="linear")
#svmfit <- svm(y~.,data=dat)
# print(svmfit)
# <<< Evaluate Error >>>
y_predict <- predict(svmfit,x_test)
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
}
mean(err_rate)
library(e1071)
model_samples <- 10000
train_samples <- 100
test_samples <- 1000
err_rate <- rep(NULL,times=model_samples)
for (i in 1:model_samples)
{
# <<< Training Data >>>
x_train <- matrix(rnorm(train_samples*10),train_samples,10)             # 10 Rows (dimensions), 50 Columns (samples)
y_train <- rep(c(0,1),c(train_samples/2,train_samples/2))               # Set half of the y's as class 0 and the other as class 1
x_train[y_train==1,1:5] <- x_train[y_train==1,1:5] + 1                  # Offset the mean of first 5 dimensions
# --- Checking ---
colMeans(x_train[y_train==1,])
# <<< Test Data >>>
x_test <- matrix(rnorm(test_samples*10),test_samples,10)                # 10 Rows (dimensions), 50 Columns (samples)
y_test <- rep(c(0,1),c(test_samples/2,test_samples/2))                  # Set half of the y's as class 0 and the other as class 1
x_test[y_test==1,1:5] <- x_test[y_test==1,1:5] + 1                      # Offset the mean of first 5 dimensions
# <<< Fit Model >>>
dat <- data.frame(x=x_train,y=as.factor(y_train))
svmfit <- glm(y~.,data=dat,family=binomial)
#svmfit <- svm(y~.,data=dat,kernel="linear")
#svmfit <- svm(y~.,data=dat)
# print(svmfit)
# <<< Evaluate Error >>>
y_predict <- predict(svmfit,x_test)
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
}
mean(err_rate)
class(dat)
svmfit <- glm(y~.,data=dat,family=binomial)
y_predict <- predict(svmfit,x_test)
svmfit
dat_test <- data.frame(x=x_test,y=as.factor(y_test))
y_predict <- predict(svmfit,dat_test,type="response")
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
library(e1071)
model_samples <- 10000
train_samples <- 100
test_samples <- 1000
err_rate <- rep(NULL,times=model_samples)
for (i in 1:model_samples)
{
# <<< Training Data >>>
x_train <- matrix(rnorm(train_samples*10),train_samples,10)             # 10 Rows (dimensions), 50 Columns (samples)
y_train <- rep(c(0,1),c(train_samples/2,train_samples/2))               # Set half of the y's as class 0 and the other as class 1
x_train[y_train==1,1:5] <- x_train[y_train==1,1:5] + 1                  # Offset the mean of first 5 dimensions
# --- Checking ---
colMeans(x_train[y_train==1,])
# <<< Test Data >>>
x_test <- matrix(rnorm(test_samples*10),test_samples,10)                # 10 Rows (dimensions), 50 Columns (samples)
y_test <- rep(c(0,1),c(test_samples/2,test_samples/2))                  # Set half of the y's as class 0 and the other as class 1
x_test[y_test==1,1:5] <- x_test[y_test==1,1:5] + 1                      # Offset the mean of first 5 dimensions
# <<< Fit Model >>>
dat <- data.frame(x=x_train,y=as.factor(y_train))
svmfit <- glm(y~.,data=dat,family=binomial)
#svmfit <- svm(y~.,data=dat,kernel="linear")
#svmfit <- svm(y~.,data=dat)
# print(svmfit)
# <<< Evaluate Error >>>
dat_test <- data.frame(x=x_test,y=as.factor(y_test))
y_predict <- predict(svmfit,dat_test,type="response")
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
}
mean(err_rate)
y_predict
y_test
dat <- data.frame(x=x_train,y=as.factor(y_train))
svmfit <- glm(y~.,data=dat,family=binomial)
dat_test <- data.frame(x=x_test,y=as.factor(y_test))
y_predict <- predict(svmfit,dat_test)
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
y_predict
y_predict <- ifelse(y_response > 0.5, 0, 1)
y_response <- predict(svmfit,dat_test)
y_predict <- ifelse(y_response > 0.5, 0, 1)
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
library(e1071)
model_samples <- 10000
train_samples <- 100
test_samples <- 1000
err_rate <- rep(NULL,times=model_samples)
for (i in 1:model_samples)
{
# <<< Training Data >>>
x_train <- matrix(rnorm(train_samples*10),train_samples,10)             # 10 Rows (dimensions), 50 Columns (samples)
y_train <- rep(c(0,1),c(train_samples/2,train_samples/2))               # Set half of the y's as class 0 and the other as class 1
x_train[y_train==1,1:5] <- x_train[y_train==1,1:5] + 1                  # Offset the mean of first 5 dimensions
# --- Checking ---
colMeans(x_train[y_train==1,])
# <<< Test Data >>>
x_test <- matrix(rnorm(test_samples*10),test_samples,10)                # 10 Rows (dimensions), 50 Columns (samples)
y_test <- rep(c(0,1),c(test_samples/2,test_samples/2))                  # Set half of the y's as class 0 and the other as class 1
x_test[y_test==1,1:5] <- x_test[y_test==1,1:5] + 1                      # Offset the mean of first 5 dimensions
# <<< Fit Model >>>
dat <- data.frame(x=x_train,y=as.factor(y_train))
svmfit <- glm(y~.,data=dat,family=binomial)
#svmfit <- svm(y~.,data=dat,kernel="linear")
#svmfit <- svm(y~.,data=dat)
# print(svmfit)
# <<< Evaluate Error >>>
dat_test <- data.frame(x=x_test,y=as.factor(y_test))
y_response <- predict(svmfit,dat_test)
y_predict <- ifelse(y_response > 0.5, 1, 0)
err_rate[i] <- (sum(y_predict != y_test))/test_samples
message(paste0("Model Sample #",as.character(i)," error rate: ",as.character(err_rate[i]*100),"%"))
}
mean(err_rate)
.71^2 + .71^2
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
pca.out$scale
?prcomp
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
load('Statistical_Learning/10.R.RData')
X <- rbind(x,x.test)
pca.out <- procom(X, scale=)
pca.out <- prcomp(X, scale=TRUE)
pra.out$sd
pra.out$sdev
pca.out$sd
names(pca.out)
prvar <- pca.out$sd^2/sum(pca.out$sd^2)
sum(prvar[1:5])
xall <- rbind (x, x.test)
prfit <- prcomp(xall, scale=T)
prvar <- prfit$sd^2/sum(prfit$sd^2)
sum(prvar[1:5])
xall <- rbind (x, x.test)
prfit2 <- prcomp(xall, scale=T)
xrt <- as.matrix(x) %*% as.matrix(prfit2$rotation[,1:5])
xyt5 <- data.frame(y, xrt)
lmfit5 <- lm (y ~. , data=xyt5 )
xrs <- as.matrix(x.test) %*% as.matrix(prfit2$rotation[,1:5])
xys5 <- data.frame(y.test, xrs)
yp5 <- predict (lmfit5, newdata=xys5 )
mean((yp5 - y.test)^2)
train = data.frame(y,x)
lm.raw.fit <- lm(y~., data = train)
pred <- predict(lm.raw.fit, newdata = x.test)
mean((pred-y.test)^2)
data()
require("women")
women
?read.csv
?read.table
install.packages("quantmod")
install.packages("quantmod")
library("quantmod")
getSymbols('APPL')
getSymbols('APPL')
getSymbols('AAPL')
barChart("AAPL")
barChart(AAPL)
?save
?save.image
?head
head(AAPL)
str(AAPL)
colname(AAPL)
colnames(AAPL)
rownames(AAPL)
library(psych)
mode(AAPL)
mtcars
names(mtcars)
?apply
ls
?install.packages
wd()
getwd()
install.packages("Rcode_snippet/Packages/dmr.data_1.0.tar.gz")
install.packages("file://~/Home/Coding/R/Rcode_snippet/Packages/dmr.data_1.0.tar.gz")
install.packages("file://~/Home/Coding/R/Rcode_snippet/Packages/dmr.data_1.0.tar.gz", repos=NULL)
install.packages("Rcode_snippet/Packages/dmr.data_1.0.tar.gz", repos=NULL)
install.packages("~/Home/Coding/R/Rcode_snippet/Packages/dmr.data_1.0.tar.gz", repos=NULL)
install.packages("~/Home/Coding/R/Rcode_snippet/Packages/dmr.data", repos=NULL)
require(dmr.data)
?dmr.data
dmr.data
weather <- read.table(text="
outlook temperature humidity   wind play
1    sunny         hot     high normal   no
2    sunny         hot     high   high   no
3 overcast         hot     high normal  yes
4    rainy        mild     high normal  yes
5    rainy        cold   normal normal  yes
6    rainy        cold   normal   high   no
7 overcast        cold   normal   high  yes
8    sunny        mild     high normal   no
9    sunny        cold   normal normal  yes
10   rainy        mild   normal normal  yes
11    sunny        mild   normal   high  yes
12 overcast        mild     high   high  yes
13 overcast         hot   normal normal  yes
14    rainy        mild     high   high   no")
summary(weather)
names(weather)
require(dmr.data)
weatherc
names(dmr.data)
weatherc <- read.table(text="
outlook temperature humidity   wind play
1     sunny          27       80 normal   no
2     sunny          28       65   high   no
3  overcast          29       90 normal  yes
4     rainy          21       75 normal  yes
5     rainy          17       40 normal  yes
6     rainy          15       25   high   no
7  overcast          19       50   high  yes
8     sunny          22       95 normal   no
9     sunny          18       45 normal  yes
10     rainy          23       30 normal  yes
11     sunny          24       55   high  yes
12  overcast          25       70   high  yes
13  overcast          30       35 normal  yes
14     rainy          26       85   high   no")
summary(weatherc)
?data
data(weather, package="dmr.data")
data(weatherc, package="dmr.data"
data(weatherr, package="dmr.data")
data(weatherc, package="dmr.data")
data(weatherr, package="dmr.data")
weatherr
?weighted.mean
?order
install.packages("~/Coding/R/Rcode_snippet/Packages/dmr.util_1.0.tar.gz")
install.packages("~/Coding/R/Rcode_snippet/Packages/dmr.util_1.0.tar.gz", repo=NULL)
require(dmr.util)
?weighted.median
weighted.median
?function
d
?median
?rank
rank(weatherr$playability)
weatherr$playability
?quantile
quantile(weatherc$temperature)
?weighted.variance
?boxplot
boxplot(weatherc$temperature)
boxplot(weatherc$temperature, range=0.5)
boxplot(weatherc$temperature, range=0.49)
boxplot(weatherc$temperature, range=0.5, plot=False)
boxplot(weatherc$temperature, range=0.5, plot=FALSE)
?flevels
modal <- function(v)
{
m <- which.max(table(v))
if (is.factor(v))
flevels(v)[m]
else
sort(unique(v))[m]
}
# demonstration
modal(weather$outlook)
modal(weatherr$temperature)
weather$outlook
?which.max
which.max(weather$temperature)
weather$temperature
which.max(weatherc$temperature)
weatherc$temperature
talbe(weather$outlook)
table(weather$outlook)
?cor.test
cor.test(weatherr$temperature, weatherr$playability, method="pearson")
cor.test(weatherr$temperature, weatherr$playability, method="spearman")
?chisq.test
chisq.test(weather$outlook, weather$play)
library(dmr.claseval)
?install.packages
install.packages("~/Coding/R/Rcode_snippet/Packages/dmr.claseval_1.0.tar.gz", repos=NULL)
install.packages("file://~/Coding/R/Rcode_snippet/Packages/dmr.claseval_1.0.tar.gz", repos=NULL)
install.packages(file://~/Coding/R/Rcode_snippet/Packages/dmr.claseval_1.0.tar.gz, repos=NULL)
install.packages(pkgs="file://~/Coding/R/Rcode_snippet/Packages/dmr.claseval_1.0.tar.gz", repos=NULL)
library(dmr.claseval)
library(dmr.stats)
library(dmr.util)
library(rpart)
library(rpart.plot)
library(lattice)
data(weather, package="dmr.data")
data(weatherc, package="dmr.data")
weather
weartherc
weatherc
?rpart
install.packages(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
?expand.grid
dtdat <- expand.grid(a1=seq(1, 10, 3), a2=seq(1, 10, 3))
dtdat
?ifesle
?ifelse
dtdat$c <- as.factor(ifelse(dtdat$a1<=7 & dtdat$a2<=1, 1,
ifelse(dtdat$a1<=7 & dtdat$a2<=7, 2,
ifelse(dtdat$a1<=7, 3,
ifelse(dtdat$a2<=4, 4, 5)))))
prp(rpart(c~., dtdat, minsplit=2, cp=0))
levelplot(c~a1*a2, dtdat, at=0.5+0:5, col.regions=gray(seq(0.1, 0.9, 0.1)),
colorkey=list(at=0.5+0:5))
?prp
?rpart
dtdat
?levelplot
?prp
data <- weather
attributes <- names(weather)[1:4]
class <- names(weather)[5]
init <- function()
{
clabs <<- factor(levels(data[[class]]),
levels=levels(data[[class]]))      # class labels
tree <<- data.frame(node=1, attribute=NA, value=NA, class=NA, count=NA,
`names<-`(rep(list(NA), length(clabs)),
paste("p", clabs, sep=".")))
cprobs <<- (ncol(tree)-length(clabs)+1):ncol(tree)  # class probability columns
nodemap <<- rep(1, nrow(data))
n <<- 1
}
n <<- 1
n
?<<-
?levels
levels(data[[class]])
?factor
init()
clabs
tree
cprobs
nodemap
n
ncol(tree)
(rep(list(NA), length(clabs)),
paste("p", clabs, sep="."))
(rep(list(NA), length(clabs)),paste("p", clabs, sep="."))
rep(list(NA), length(clabs)),paste("p", clabs, sep="."))
list(NA)
tree
clabs
data[class]
?levels
?paste
cprobs
paste("p", clabs, sep=".")
`names<-`(rep(list(NA), length(clabs)),
paste("p", clabs, sep="."))
`names<-`
?`names<-`
?==
n
tree
tree$node==n
nodemap
?pdisc
class.distribution <- function(n)
{
tree$count[tree$node==n] <<- sum(nodemap==n)
tree[tree$node==n,cprobs] <<- pdisc(data[nodemap==n,class])
}
class.distribution(n)
tree
data[nodemap==n, class]
data[TRUE]
sum(nodemap)
sum(nodemap==n)
tree[tree$node!=n,cprobs]
tree[tree$node==n,cprobs]
data[FALSE,class]
ls
getwd()
setwd("./ESL/")
prostate <- read.table("prostate.data", sep=" ")
prostate <- read.table("prostate.data", header = TRUE, sep=" ")
?read.table
prostate <- read.table("prostate.data", header = TRUE, sep=" ", fill=TRUE)
prostate <- read.table("prostate.data", header = TRUE, sep=" ")
prostate <- read.table("prostate.data", header = TRUE, sep="\t")
names(prostate)
prostate[1,]
prostate[,1]
prostate <- prostate[,-1]
x <- prostate[, -c(9,10)]
?scale
xp <- scale(x)
class(xp)
pairs(xp)
names(xp)
x <- prostate[, -10]
xp <- scale(x)
pairs(xp)
?cov
names(x)
seq(2,8)
cov(xp[seq(2.8)])
cov(xp[seq(2,8)])
xp[seq(2,3)]
cov(xp[, seq(2,8)])
cov(xp)
names(prostate)
training_index <- prostate$train == "T"
training_set <- prostate[training_index, ]
class(prostate$train)
training_set <- prostate[prostate$train, ]
rm(training_index)
test_set <- prostate[-training_set,]
test_set <- prostate[-prostate$train, ]
test_set <- prostate[prostate$train == FALSE, ]
cov(scale(training_set))
training_set <- prostate[prostate$train, -10]
test_set <- prostate[prostate$train == FALSE, -10]
cov(scale(training_set))
lr <- lm(lspa ~ ., data=training_set)
lr <- lm(lpsa ~ ., data=training_set)
lr
summary(lr)
training_set <- scale(training_set)
training_set <- data.frame(scale(training_set))
names(training_set)
test_set <- data.frame(scale(test_set))
lr <- lm(lpsa ~ ., data=training_set)
summary(lr)
cov(trainging_set)
cov(training_set)
training_set <- prostate[prostate$train, -10]
lr <- lm(lpsa ~ ., data=training_set)
summary(lr)
training_set <- data.frame(scale(training_set))
lr <- lm(lpsa ~ ., data=training_set)
summary(lr)
mean(training_set$lweight)
?scale
x <- matrix(1:10, ncol = 2)
x
scale(x)
x <- prostate[, -10]
?var
var(training_set$lweight)
training_set <- data.frame(scale(training_set, center = FALSE))
training_set <- data.frame(scale(training_set, center = FALSE))
var(training_set$lweight)
lr <- lm(lpsa ~ ., data=training_set)
summary(lr)
lr <- lm(lpsa ~ ., data=data.frame(xp))
summary(lr)
?lm
prostate <- read.table("prostate.data", header = TRUE, sep = "\t")
prostate <- prostate[, -1]
training_set <- prostate[prostate$train, -10]
test_set <- prostate[prostate$train == FALSE, -10]
training_set <- data.frame(scale(training_set))
test_set <- data.frame(scale(test_set))
cov(training_set)
lr <- lm(lpsa ~ ., data = training_set)
summary(lr)
predict_lr <- predict(lr, test_set)
ME <- sum((test_set$lpsa - predict-lr)^2)
ME <- sum((test_set$lpsa - predict_lr)^2)
ME
ME <- sum((test_set$lpsa - predict_lr)^2)/length(predict_lr)
ME
?abs
ME <- sum(abs(test_set$lpsa - predict_lr))/length(predict_lr)
ME
test_set$lpsa - predict_lr
(test_set$lpsa - predict_lr)^2
ME <- sum((test_set$lpsa - predict_lr)^2)/length(predict_lr)
ME
library("xtable")
install.packages("xtable")
?xtable
??xtable
library(xtable)
?xtable
cov(training_set)
cov(training_set[,-9])
lr <- lm(lpsa ~ ., data = training_set)
summary(lr)
?lm
names(lr)
lr$coefficients
ME <- sum((test_set$lpsa - predict_lr)^2)/length(predict_lr)
ME
